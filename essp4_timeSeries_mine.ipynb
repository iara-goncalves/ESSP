{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b712e145-b276-4c7b-b157-d00d3e8492c4",
   "metadata": {},
   "source": [
    "# Work With Time Series File For ESSP4\n",
    "There is one time series file for each data set of the form: `DS#_timeSeries.csv`\n",
    "\n",
    "For example, the relevant file for data set three (3) would be: `DS3_timeSeries.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f66531-e7d7-4d34-ad67-ddc8ade51881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import errorbar\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.signal import lombscargle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5707e7f4-74f2-43d5-a0ba-d960f6c49b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify where all the data set folders are\n",
    "essp_dir = \"/work2/lbuc/data/ESSP4/ESSP4\"\n",
    "\n",
    "# Columns to test for outliers\n",
    "cols_to_clip = [\n",
    "    \"RV [m/s]\",\n",
    "    \"BIS [m/s]\",\n",
    "    \"CCF FWHM [m/s]\",\n",
    "    \"CCF Contrast\",\n",
    "    \"H-alpha Emission\",\n",
    "    \"CaII Emission\"\n",
    "]\n",
    "\n",
    "sigma_threshold = 4\n",
    "\n",
    "# Control whether .dat files exclude outliers\n",
    "exclude_outliers_when_writing = True\n",
    "\n",
    "# Output directories\n",
    "outdir = \"/work2/lbuc/iara/GitHub/PyORBIT_examples/ESSP4/data\"\n",
    "fig_dir = \"/work2/lbuc/iara/GitHub/ESSP/Figures\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ca93e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of combined dataframe:\n",
      "         Standard File Name   Time [eMJD]   RV [m/s]  RV Err. [m/s]  \\\n",
      "0  DS1.001_spec_harpsn.fits  59337.993481   9.825036          0.103   \n",
      "1  DS1.002_spec_harpsn.fits  59337.997242   9.733036          0.103   \n",
      "2  DS1.003_spec_harpsn.fits  59338.004754  12.039036          0.103   \n",
      "3  DS1.004_spec_expres.fits  59338.301795  10.673016          0.110   \n",
      "4  DS1.005_spec_expres.fits  59338.304359  10.135016          0.110   \n",
      "\n",
      "   Exp. Time [s]   Airmass  BERV [km/s] Instrument   CCF Contrast  \\\n",
      "0     300.000000  1.125065    -0.581131     harpsn -457837.489595   \n",
      "1     300.000000  1.130287    -0.590573     harpsn -457800.591871   \n",
      "2     300.000000  1.142726    -0.609293     harpsn -457678.316202   \n",
      "3     185.271000  1.306683    -0.000004     expres -354050.782988   \n",
      "4     185.887999  1.317263    -0.000004     expres -354268.748737   \n",
      "\n",
      "   CCF Contrast Err.  BIS [m/s]  H-alpha Emission  CaII Emission Dataset  \\\n",
      "0         543.369488 -51.516667          0.173834       0.100046     DS1   \n",
      "1         550.192273 -50.216667          0.172751       0.100664     DS1   \n",
      "2         557.232302 -49.500000          0.174994       0.107149     DS1   \n",
      "3         544.182192 -76.200000          0.172216       0.103057     DS1   \n",
      "4         553.370636 -73.850000          0.172323       0.100985     DS1   \n",
      "\n",
      "   CCF FWHM [m/s]  CCF FWHM Err. [m/s]  \n",
      "0     6856.193834            12.189541  \n",
      "1     6857.638064            12.348111  \n",
      "2     6856.078859            12.508341  \n",
      "3     6692.954071            15.302120  \n",
      "4     6690.431513            15.546367  \n",
      "Total points loaded: 2669\n"
     ]
    }
   ],
   "source": [
    "# All data sets together\n",
    "\n",
    "# Create a list to collect all dataframes\n",
    "df_list = []\n",
    "\n",
    "# Loop over dataset 1 to 9\n",
    "for dset_num in range(1, 10):\n",
    "    file_path = os.path.join(essp_dir, f'DS{dset_num}', f'DS{dset_num}_timeSeries.csv')\n",
    "    if os.path.exists(file_path):\n",
    "        df_tmp = pd.read_csv(file_path)\n",
    "        df_tmp[\"Dataset\"] = f\"DS{dset_num}\"\n",
    "\n",
    "        # Convert FWHM from km/s → m/s\n",
    "        if \"CCF FWHM [km/s]\" in df_tmp.columns:\n",
    "            df_tmp[\"CCF FWHM [m/s]\"] = df_tmp[\"CCF FWHM [km/s]\"] * 1000.0\n",
    "            # drop the old km/s column:\n",
    "            df_tmp = df_tmp.drop(columns=[\"CCF FWHM [km/s]\"])\n",
    "        \n",
    "        if \"CCF FWHM Err. [km/s]\" in df_tmp.columns:\n",
    "            df_tmp[\"CCF FWHM Err. [m/s]\"] = df_tmp[\"CCF FWHM Err. [km/s]\"] * 1000.0\n",
    "            # drop the old km/s column:\n",
    "            df_tmp = df_tmp.drop(columns=[\"CCF FWHM Err. [km/s]\"])\n",
    "\n",
    "        df_list.append(df_tmp)\n",
    "    else:\n",
    "        print(f\"Warning: file not found {file_path}\")\n",
    "\n",
    "# Combine into one big dataframe\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Head of combined dataframe:\")\n",
    "print(df_all.head())\n",
    "print(\"Total points loaded:\", len(df_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc65e5d",
   "metadata": {},
   "source": [
    "### Applying 5 sigma for outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450c6a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers flagged (but kept): 13  (0.49%)\n"
     ]
    }
   ],
   "source": [
    "# Create an 'is_outlier' column initialized to False\n",
    "df_all[\"is_outlier\"] = False\n",
    "\n",
    "# Compute outliers per dataset, using ANY column exceeding 5σ from that dataset's mean\n",
    "for ds, g in df_all.groupby(\"Dataset\"):\n",
    "    idx = g.index\n",
    "    out_mask = np.zeros(len(g), dtype=bool)\n",
    "\n",
    "    for col in cols_to_clip:\n",
    "        if col not in g.columns:\n",
    "            continue\n",
    "        x = g[col].dropna().astype(float)\n",
    "        if len(x) == 0:\n",
    "            continue\n",
    "            \n",
    "        median = x.median()\n",
    "        std = x.std(ddof=1)\n",
    "        if std == 0 or np.isnan(std):\n",
    "            continue\n",
    "            \n",
    "        # Points beyond sigma_threshold - ACCUMULATE outliers (use |= instead of =)\n",
    "        col_outliers = (np.abs(g[col] - median) > (sigma_threshold * std))\n",
    "        out_mask |= col_outliers.fillna(False)  # Handle NaN values\n",
    "\n",
    "    # Assign back\n",
    "    df_all.loc[idx, \"is_outlier\"] = out_mask\n",
    "\n",
    "# Quick summary\n",
    "n_out = df_all[\"is_outlier\"].sum()\n",
    "print(f\"Outliers flagged (but kept): {n_out}  ({n_out/len(df_all)*100:.2f}%)\")\n",
    "# df_all[df_all[\"is_outlier\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd761bad",
   "metadata": {},
   "source": [
    "## Create DS.dat files for job submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4456de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .dat files using INLIERS only.\n"
     ]
    }
   ],
   "source": [
    "# Choose which dataframe to export\n",
    "if exclude_outliers_when_writing:\n",
    "    df_export = df_all[~df_all.is_outlier].copy()   # inliers only\n",
    "    print(\"Writing .dat files using INLIERS only.\")\n",
    "else:\n",
    "    df_export = df_all.copy()\n",
    "    print(\"Writing .dat files using ALL points (including outliers).\")\n",
    "\n",
    "\n",
    "###### RV ######\n",
    "# Loop over datasets\n",
    "for ds, subdf in df_export.groupby(\"Dataset\"):\n",
    "\n",
    "    # Get instruments present in this dataset\n",
    "    instruments = sorted(subdf[\"Instrument\"].unique())\n",
    "    instrument_map = {inst: i for i, inst in enumerate(instruments)}\n",
    "\n",
    "    \n",
    "    # Columns\n",
    "    time = subdf[\"Time [eMJD]\"].values\n",
    "    rv = subdf[\"RV [m/s]\"].values\n",
    "    rv_err = subdf[\"RV Err. [m/s]\"].values\n",
    "    jitter_flag = np.zeros(len(subdf), dtype=int)        # all 0\n",
    "    offset_flag = subdf[\"Instrument\"].map(instrument_map).astype(int).values\n",
    "    subset_flag = -1 * np.ones(len(subdf), dtype=int)    # all -1\n",
    "\n",
    "    # Combine\n",
    "    data = np.column_stack([time, rv, rv_err, jitter_flag, offset_flag, subset_flag])\n",
    "\n",
    "    # Save to .dat file\n",
    "    outfile = os.path.join(outdir, f\"{ds}_RV.dat\")\n",
    "    np.savetxt(outfile, data, fmt=[\"%.6f\", \"%.6f\", \"%.6f\", \"%d\", \"%d\", \"%d\"])\n",
    "\n",
    "\n",
    "###### BIS and FWHM ######\n",
    "\n",
    "# Empirical errors\n",
    "bis_err_val = 0.95      # m/s\n",
    "fwhm_err_val = 5.0    # m/s\n",
    "halpha_err_val = 0.001  # 1/s\n",
    "ca2_err_val = 0.003  # 1/s\n",
    "\n",
    "# Loop over datasets\n",
    "for ds, subdf in df_export.groupby(\"Dataset\"):\n",
    "\n",
    "    # Get instruments present in this dataset\n",
    "    instruments = sorted(subdf[\"Instrument\"].unique())\n",
    "    instrument_map = {inst: i for i, inst in enumerate(instruments)}\n",
    "\n",
    "    time = subdf[\"Time [eMJD]\"].values\n",
    "    \n",
    "    # =====================\n",
    "    # BIS\n",
    "    # =====================\n",
    "    bis = subdf[\"BIS [m/s]\"].values\n",
    "    bis_err = np.full(len(subdf), bis_err_val)   # constant error\n",
    "    jitter_flag = np.zeros(len(subdf), dtype=int)\n",
    "    offset_flag = subdf[\"Instrument\"].map(instrument_map).astype(int).values\n",
    "    subset_flag = -1 * np.ones(len(subdf), dtype=int)\n",
    "\n",
    "    bis_data = np.column_stack([time, bis, bis_err, jitter_flag, offset_flag, subset_flag])\n",
    "    bis_outfile = os.path.join(outdir, f\"{ds}_BIS.dat\")\n",
    "    np.savetxt(bis_outfile, bis_data, fmt=[\"%.6f\", \"%.6f\", \"%.6f\", \"%d\", \"%d\", \"%d\"])\n",
    "\n",
    "    # =====================\n",
    "    # FWHM\n",
    "    # =====================\n",
    "    fwhm = subdf[\"CCF FWHM [m/s]\"].values\n",
    "    fwhm_err = np.full(len(subdf), fwhm_err_val) # constant error\n",
    "    jitter_flag = np.zeros(len(subdf), dtype=int)\n",
    "    offset_flag = subdf[\"Instrument\"].map(instrument_map).astype(int).values\n",
    "    subset_flag = -1 * np.ones(len(subdf), dtype=int)\n",
    "\n",
    "    fwhm_data = np.column_stack([time, fwhm, fwhm_err, jitter_flag, offset_flag, subset_flag])\n",
    "    fwhm_outfile = os.path.join(outdir, f\"{ds}_FWHM.dat\")\n",
    "    np.savetxt(fwhm_outfile, fwhm_data, fmt=[\"%.6f\", \"%.6f\", \"%.6f\", \"%d\", \"%d\", \"%d\"])\n",
    "\n",
    "    # =====================\n",
    "    # H alpha\n",
    "    # =====================\n",
    "    halpha = subdf[\"H-alpha Emission\"].values\n",
    "    halpha_err = np.full(len(subdf), halpha_err_val) # constant error\n",
    "    jitter_flag = np.zeros(len(subdf), dtype=int)\n",
    "    offset_flag = subdf[\"Instrument\"].map(instrument_map).astype(int).values\n",
    "    subset_flag = -1 * np.ones(len(subdf), dtype=int)\n",
    "\n",
    "    halpha_data = np.column_stack([time, halpha, halpha_err, jitter_flag, offset_flag, subset_flag])\n",
    "    halpha_outfile = os.path.join(outdir, f\"{ds}_Halpha.dat\")\n",
    "    np.savetxt(halpha_outfile, halpha_data, fmt=[\"%.6f\", \"%.6f\", \"%.6f\", \"%d\", \"%d\", \"%d\"])\n",
    "\n",
    "    # =====================\n",
    "    # CaII\n",
    "    # =====================\n",
    "    ca2 = subdf[\"CaII Emission\"].values\n",
    "    ca2_err = np.full(len(subdf), ca2_err_val) # constant error\n",
    "    jitter_flag = np.zeros(len(subdf), dtype=int)\n",
    "    offset_flag = subdf[\"Instrument\"].map(instrument_map).astype(int).values\n",
    "    subset_flag = -1 * np.ones(len(subdf), dtype=int)\n",
    "\n",
    "    ca2_data = np.column_stack([time, ca2, ca2_err, jitter_flag, offset_flag, subset_flag])\n",
    "    ca2_outfile = os.path.join(outdir, f\"{ds}_CaII.dat\")\n",
    "    np.savetxt(ca2_outfile, ca2_data, fmt=[\"%.6f\", \"%.6f\", \"%.6f\", \"%d\", \"%d\", \"%d\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819132ed-6562-4721-bfc6-be6075863799",
   "metadata": {},
   "source": [
    "## Activity Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d2c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS1_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS2_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS3_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS4_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS5_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS6_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS7_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS8_activity.png\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS9_activity.png\n"
     ]
    }
   ],
   "source": [
    "####### Friday 5th September #########\n",
    "\n",
    "def plot_dataset_activity(ds, ds_df, fig_dir):\n",
    "    \"\"\"\n",
    "    Plot activity indicators for a single dataset with outliers highlighted.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(6, 1, figsize=(12, 18), sharex=True)\n",
    "\n",
    "    plot_info = [\n",
    "        (\"RV [m/s]\", \"RV Err. [m/s]\", \"RV [m/s]\"),\n",
    "        (\"CCF Contrast\", None, \"CCF Contrast\"),\n",
    "        (\"CCF FWHM [m/s]\", None, \"CCF FWHM [m/s]\"),\n",
    "        (\"BIS [m/s]\", None, \"BIS [m/s]\"),\n",
    "        (\"H-alpha Emission\", None, \"H-alpha Emission\"),\n",
    "        (\"CaII Emission\", None, \"CaII Emission\"),\n",
    "    ]\n",
    "    \n",
    "    # Fixed error values for columns without error columns\n",
    "    fixed_errors = {\n",
    "        \"CCF Contrast\": 130,\n",
    "        \"CCF FWHM [m/s]\": 5.0,\n",
    "        \"BIS [m/s]\": 0.95,\n",
    "        \"H-alpha Emission\": 0.001,\n",
    "        \"CaII Emission\": 0.003,\n",
    "    }\n",
    "\n",
    "    # Get all unique instruments in this dataset\n",
    "    all_instruments = sorted(ds_df[\"Instrument\"].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(all_instruments)))\n",
    "    color_map = dict(zip(all_instruments, colors))\n",
    "\n",
    "    for ax, (col, err_col, ylabel) in zip(axes, plot_info):\n",
    "        if col not in ds_df.columns:\n",
    "            ax.text(0.5, 0.5, f\"Column '{col}' not found\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_ylabel(ylabel)\n",
    "            continue\n",
    "\n",
    "        # Calculate instrument-specific medians for centering\n",
    "        inst_medians = ds_df.groupby(\"Instrument\")[col].median()\n",
    "        \n",
    "        # Plot each instrument separately\n",
    "        for inst in all_instruments:\n",
    "            inst_data = ds_df[ds_df[\"Instrument\"] == inst].copy()\n",
    "            if inst_data.empty:\n",
    "                continue\n",
    "                \n",
    "            # Center data by instrument median\n",
    "            center = inst_medians[inst]\n",
    "            y_centered = inst_data[col] - center\n",
    "            \n",
    "            # Determine error values\n",
    "            if err_col and err_col in inst_data.columns:\n",
    "                yerr = inst_data[err_col]\n",
    "            else:\n",
    "                yerr = fixed_errors.get(col, 1.0)\n",
    "            \n",
    "            # Split into inliers and outliers\n",
    "            inliers = inst_data[~inst_data[\"is_outlier\"]]\n",
    "            outliers = inst_data[inst_data[\"is_outlier\"]]\n",
    "            \n",
    "            # Plot inliers\n",
    "            if not inliers.empty:\n",
    "                y_in = inliers[col] - center\n",
    "                if isinstance(yerr, pd.Series):\n",
    "                    yerr_in = yerr.loc[inliers.index]\n",
    "                else:\n",
    "                    yerr_in = yerr\n",
    "                    \n",
    "                ax.errorbar(inliers[\"Time [eMJD]\"], y_in, yerr=yerr_in,\n",
    "                           fmt=\".\", color=color_map[inst], label=inst, \n",
    "                           alpha=0.8, markersize=6)\n",
    "            \n",
    "            # Plot outliers\n",
    "            if not outliers.empty:\n",
    "                y_out = outliers[col] - center\n",
    "                if isinstance(yerr, pd.Series):\n",
    "                    yerr_out = yerr.loc[outliers.index]\n",
    "                else:\n",
    "                    yerr_out = yerr\n",
    "                    \n",
    "                ax.errorbar(outliers[\"Time [eMJD]\"], y_out, yerr=yerr_out,\n",
    "                           fmt=\"o\", color=\"black\", alpha=0.7, markersize=8,\n",
    "                           markeredgecolor=\"red\", markeredgewidth=1.5)\n",
    "\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add outlier legend entry only once\n",
    "    if df_all[\"is_outlier\"].any():\n",
    "        axes[0].errorbar([], [], [], fmt=\"o\", color=\"black\", alpha=0.7, \n",
    "                        markeredgecolor=\"red\", markeredgewidth=1.5, \n",
    "                        label=\"Outliers\")\n",
    "\n",
    "    axes[-1].set_xlabel(\"Time [eMJD]\")\n",
    "    \n",
    "    # Create legend with unique entries only\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    axes[0].legend(by_label.values(), by_label.keys(), loc=\"best\")\n",
    "\n",
    "    fig.suptitle(f\"{ds} Activity Indicators (Red-edged = Outliers)\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    fig_path = os.path.join(fig_dir, f\"{ds}_activity.png\")\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved figure: {fig_path}\")\n",
    "\n",
    "# Apply the improved plotting function\n",
    "for ds, ds_df in df_all.groupby(\"Dataset\"):\n",
    "    plot_dataset_activity(ds, ds_df, fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2701ff1",
   "metadata": {},
   "source": [
    "## Lomb-Scargle Periodograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3222dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating activity plots with periodograms using inliers only...\n",
      "DS1 - RV [m/s]: Top periods = 2.92d, 3.93d, 1.52d\n",
      "DS1 - CCF Contrast: Top periods = 1.15d, 2.00d, 1.54d\n",
      "DS1 - CCF FWHM [m/s]: Top periods = 2.01d, 7.92d, 1.23d\n",
      "DS1 - BIS [m/s]: Top periods = 2.00d, 1.15d, 42.57d\n",
      "DS1 - H-alpha Emission: Top periods = 1.16d, 2.01d, 2.62d\n",
      "DS1 - CaII Emission: Top periods = 1.10d, 18.53d, 31.23d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS1_activity_LS_periodograms.png\n",
      "DS2 - RV [m/s]: Top periods = 1.24d, 1.63d, 70.70d\n",
      "DS2 - CCF Contrast: Top periods = 1.22d, 2.00d, 2.62d\n",
      "DS2 - CCF FWHM [m/s]: Top periods = 39.15d, 70.70d, 1.44d\n",
      "DS2 - BIS [m/s]: Top periods = 39.43d, 2.00d, 70.70d\n",
      "DS2 - H-alpha Emission: Top periods = 1.22d, 1.65d, 2.62d\n",
      "DS2 - CaII Emission: Top periods = 1.28d, 2.00d, 3.44d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS2_activity_LS_periodograms.png\n",
      "DS3 - RV [m/s]: Top periods = 27.56d, 12.46d, 70.68d\n",
      "DS3 - CCF Contrast: Top periods = 1.55d, 4.69d, 1.13d\n",
      "DS3 - CCF FWHM [m/s]: Top periods = 1.27d, 2.01d, 8.22d\n",
      "DS3 - BIS [m/s]: Top periods = 1.55d, 8.24d, 40.86d\n",
      "DS3 - H-alpha Emission: Top periods = 1.55d, 4.66d, 1.13d\n",
      "DS3 - CaII Emission: Top periods = 1.13d, 4.67d, 2.32d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS3_activity_LS_periodograms.png\n",
      "DS4 - RV [m/s]: Top periods = 31.21d, 5.41d, 1.11d\n",
      "DS4 - CCF Contrast: Top periods = 1.82d, 1.15d, 22.99d\n",
      "DS4 - CCF FWHM [m/s]: Top periods = 2.27d, 1.78d, 43.44d\n",
      "DS4 - BIS [m/s]: Top periods = 1.82d, 22.83d, 2.68d\n",
      "DS4 - H-alpha Emission: Top periods = 1.82d, 1.15d, 2.39d\n",
      "DS4 - CaII Emission: Top periods = 2.55d, 3.54d, 6.18d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS4_activity_LS_periodograms.png\n",
      "DS5 - RV [m/s]: Top periods = 60.20d, 47.69d, 33.49d\n",
      "DS5 - CCF Contrast: Top periods = 1.29d, 2.57d, 2.00d\n",
      "DS5 - CCF FWHM [m/s]: Top periods = 22.01d, 42.06d, 16.12d\n",
      "DS5 - BIS [m/s]: Top periods = 2.86d, 23.42d, 16.73d\n",
      "DS5 - H-alpha Emission: Top periods = 1.15d, 2.86d, 2.00d\n",
      "DS5 - CaII Emission: Top periods = 2.14d, 18.91d, 1.28d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS5_activity_LS_periodograms.png\n",
      "DS6 - RV [m/s]: Top periods = 14.45d, 69.87d, 55.34d\n",
      "DS6 - CCF Contrast: Top periods = 2.62d, 1.19d, 3.37d\n",
      "DS6 - CCF FWHM [m/s]: Top periods = 39.54d, 2.01d, 1.50d\n",
      "DS6 - BIS [m/s]: Top periods = 39.73d, 2.01d, 1.50d\n",
      "DS6 - H-alpha Emission: Top periods = 1.19d, 2.61d, 3.56d\n",
      "DS6 - CaII Emission: Top periods = 1.23d, 2.60d, 12.26d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS6_activity_LS_periodograms.png\n",
      "DS7 - RV [m/s]: Top periods = 25.97d, 12.39d, 1.66d\n",
      "DS7 - CCF Contrast: Top periods = 1.78d, 2.78d, 1.35d\n",
      "DS7 - CCF FWHM [m/s]: Top periods = 1.79d, 37.20d, 4.79d\n",
      "DS7 - BIS [m/s]: Top periods = 1.85d, 37.62d, 2.79d\n",
      "DS7 - H-alpha Emission: Top periods = 1.55d, 2.54d, 1.15d\n",
      "DS7 - CaII Emission: Top periods = 1.36d, 5.56d, 8.94d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS7_activity_LS_periodograms.png\n",
      "DS8 - RV [m/s]: Top periods = 72.36d, 5.33d, 1.57d\n",
      "DS8 - CCF Contrast: Top periods = 1.44d, 1.13d, 72.36d\n",
      "DS8 - CCF FWHM [m/s]: Top periods = 1.45d, 3.21d, 72.36d\n",
      "DS8 - BIS [m/s]: Top periods = 1.45d, 72.36d, 10.05d\n",
      "DS8 - H-alpha Emission: Top periods = 1.24d, 2.39d, 7.52d\n",
      "DS8 - CaII Emission: Top periods = 1.20d, 2.39d, 8.50d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS8_activity_LS_periodograms.png\n",
      "DS9 - RV [m/s]: Top periods = 13.85d, 28.90d, 2.47d\n",
      "DS9 - CCF Contrast: Top periods = 1.27d, 2.29d, 5.28d\n",
      "DS9 - CCF FWHM [m/s]: Top periods = 5.34d, 1.50d, 8.96d\n",
      "DS9 - BIS [m/s]: Top periods = 1.27d, 5.35d, 2.06d\n",
      "DS9 - H-alpha Emission: Top periods = 1.27d, 2.47d, 5.64d\n",
      "DS9 - CaII Emission: Top periods = 1.28d, 2.30d, 1.71d\n",
      "Saved figure: /work2/lbuc/iara/GitHub/ESSP/Figures/DS9_activity_LS_periodograms.png\n"
     ]
    }
   ],
   "source": [
    "###### Friday 5th September - Fixed Statistics Box Position #######\n",
    "\n",
    "def plot_activity_with_periodograms(ds, ds_df, fig_dir):\n",
    "    \"\"\"\n",
    "    Plot activity indicators with Lomb-Scargle periodograms using only inliers.\n",
    "    Left column: Activity data, Right column: Periodograms\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(6, 2, figsize=(18, 18))\n",
    "    \n",
    "    # Define plot information: (column_name, error_value, y_label)\n",
    "    plot_info = [\n",
    "        (\"RV [m/s]\", \"RV Err. [m/s]\", \"RV [m/s]\"),\n",
    "        (\"CCF Contrast\", 130, \"CCF Contrast\"),\n",
    "        (\"CCF FWHM [m/s]\", 5.0, \"CCF FWHM [m/s]\"),\n",
    "        (\"BIS [m/s]\", 0.95, \"BIS [m/s]\"),\n",
    "        (\"H-alpha Emission\", 0.001, \"H-alpha Emission\"),\n",
    "        (\"CaII Emission\", 0.003, \"CaII Emission\"),\n",
    "    ]\n",
    "    \n",
    "    # Use only inliers\n",
    "    inliers = ds_df[~ds_df.is_outlier].copy()\n",
    "    \n",
    "    # Get all unique instruments and assign colors\n",
    "    all_instruments = sorted(inliers[\"Instrument\"].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(all_instruments)))\n",
    "    color_map = dict(zip(all_instruments, colors))\n",
    "    \n",
    "    for i, (col, yerr, ylabel) in enumerate(plot_info):\n",
    "        ax_data = axes[i, 0]      # Left column for data\n",
    "        ax_period = axes[i, 1]    # Right column for periodogram\n",
    "        \n",
    "        if col not in inliers.columns:\n",
    "            ax_data.text(0.5, 0.5, f\"Column '{col}' not found\", \n",
    "                        ha='center', va='center', transform=ax_data.transAxes)\n",
    "            ax_period.text(0.5, 0.5, f\"No data for '{col}'\", \n",
    "                          ha='center', va='center', transform=ax_period.transAxes)\n",
    "            ax_data.set_ylabel(ylabel)\n",
    "            continue\n",
    "        \n",
    "        # === LEFT SIDE: DATA PLOT ===\n",
    "        # Calculate instrument-specific medians for centering\n",
    "        inst_medians = inliers.groupby(\"Instrument\")[col].median()\n",
    "        \n",
    "        # Plot each instrument\n",
    "        for inst in all_instruments:\n",
    "            inst_data = inliers[inliers[\"Instrument\"] == inst]\n",
    "            if inst_data.empty:\n",
    "                continue\n",
    "                \n",
    "            # Center data by instrument median\n",
    "            center = inst_medians[inst]\n",
    "            y_centered = inst_data[col] - center\n",
    "            \n",
    "            # Handle error bars\n",
    "            if isinstance(yerr, str) and yerr in inst_data.columns:\n",
    "                error_values = inst_data[yerr]\n",
    "            else:\n",
    "                error_values = yerr\n",
    "            \n",
    "            ax_data.errorbar(inst_data[\"Time [eMJD]\"], y_centered, \n",
    "                           yerr=error_values, fmt=\".\", \n",
    "                           color=color_map[inst], label=inst, \n",
    "                           alpha=0.8, markersize=6)\n",
    "        \n",
    "        ax_data.set_ylabel(f\"{ylabel} - mean\")\n",
    "        ax_data.grid(True, alpha=0.3)\n",
    "        \n",
    "        # === RIGHT SIDE: LOMB-SCARGLE PERIODOGRAM ===\n",
    "        try:\n",
    "            if not inliers.empty and col in inliers.columns:\n",
    "                # Prepare data for periodogram (all inliers, all instruments combined)\n",
    "                time_data = inliers[\"Time [eMJD]\"].values\n",
    "                y_data = inliers[col].values\n",
    "                \n",
    "                # Handle error values\n",
    "                if isinstance(yerr, str) and yerr in inliers.columns:\n",
    "                    dy_data = inliers[yerr].values\n",
    "                else:\n",
    "                    dy_data = np.full_like(y_data, yerr if isinstance(yerr, (int, float)) else 1.0)\n",
    "                \n",
    "                # Remove NaN values\n",
    "                mask = ~(np.isnan(time_data) | np.isnan(y_data) | np.isnan(dy_data))\n",
    "                t = time_data[mask]\n",
    "                y = y_data[mask]\n",
    "                dy = dy_data[mask]\n",
    "                \n",
    "                if len(t) > 5:  # Need sufficient points for periodogram\n",
    "                    # Fix non-positive errors\n",
    "                    m = dy > 0\n",
    "                    if not m.all():\n",
    "                        repl = np.median(dy[m]) if m.any() else 1.0\n",
    "                        dy[~m] = repl\n",
    "                    \n",
    "                    span = t.max() - t.min()\n",
    "                    if span > 1:  # Need reasonable time span\n",
    "                        # Define period range\n",
    "                        min_period = 1.1\n",
    "                        max_period = max(2.0, 0.8 * span)\n",
    "                        f_min = 1.0 / max_period\n",
    "                        f_max = 1.0 / min_period\n",
    "                        \n",
    "                        # Create frequency grid\n",
    "                        N = 15000\n",
    "                        freq = np.linspace(f_min, f_max, N)\n",
    "                        \n",
    "                        # Compute Lomb-Scargle periodogram\n",
    "                        ls = LombScargle(t, y, dy)\n",
    "                        power = ls.power(freq)\n",
    "                        \n",
    "                        # Find top 3 peaks\n",
    "                        # Sort power values and get indices of top peaks\n",
    "                        sorted_indices = np.argsort(power)[::-1]  # Descending order\n",
    "                        \n",
    "                        # Get the top 3 peaks (avoiding very close peaks)\n",
    "                        peak_periods = []\n",
    "                        peak_powers = []\n",
    "                        peak_colors = ['red', 'orange', 'purple']\n",
    "                        peak_styles = ['--', '-.', ':']\n",
    "                        \n",
    "                        for idx in sorted_indices:\n",
    "                            period_candidate = 1.0 / freq[idx]\n",
    "                            power_candidate = power[idx]\n",
    "                            \n",
    "                            # Check if this peak is sufficiently separated from existing peaks\n",
    "                            # (avoid peaks that are too close to each other)\n",
    "                            too_close = False\n",
    "                            for existing_period in peak_periods:\n",
    "                                if abs(np.log10(period_candidate) - np.log10(existing_period)) < 0.1:  # 0.1 in log space\n",
    "                                    too_close = True\n",
    "                                    break\n",
    "                            \n",
    "                            if not too_close:\n",
    "                                peak_periods.append(period_candidate)\n",
    "                                peak_powers.append(power_candidate)\n",
    "                                \n",
    "                                if len(peak_periods) >= 3:\n",
    "                                    break\n",
    "                        \n",
    "                        # Convert to periods for plotting\n",
    "                        periods = 1.0 / freq\n",
    "                        \n",
    "                        # Plot periodogram\n",
    "                        ax_period.semilogx(periods, power, 'k-', linewidth=1)\n",
    "                        \n",
    "                        # Plot the top 3 peaks\n",
    "                        for j, (peak_period, peak_power) in enumerate(zip(peak_periods, peak_powers)):\n",
    "                            if j < len(peak_colors):\n",
    "                                ax_period.axvline(peak_period, color=peak_colors[j], \n",
    "                                                ls=peak_styles[j], lw=2, \n",
    "                                                label=f'{j+1}st Peak: {peak_period:.1f}d' if j==0 \n",
    "                                                      else f'{j+1}nd Peak: {peak_period:.1f}d' if j==1 \n",
    "                                                      else f'{j+1}rd Peak: {peak_period:.1f}d')\n",
    "                        \n",
    "                        # Add reference lines for common periods\n",
    "                        reference_periods = [1, 7, 14, 28, 100, 365]\n",
    "                        for ref_period in reference_periods:\n",
    "                            if min_period <= ref_period <= max_period:\n",
    "                                ax_period.axvline(ref_period, color='blue', alpha=0.4, \n",
    "                                                linestyle=':', linewidth=1)\n",
    "                                # Add label at top of plot - moved down slightly to avoid overlap\n",
    "                                ax_period.text(ref_period, ax_period.get_ylim()[1]*0.85, \n",
    "                                             f'{ref_period}d', rotation=90, ha='right', \n",
    "                                             va='top', fontsize=8, alpha=0.7, color='blue')\n",
    "                        \n",
    "                        ax_period.set_xlabel(\"Period [days]\")\n",
    "                        ax_period.set_ylabel(\"LS Power\")\n",
    "                        ax_period.set_title(f\"{ylabel} Periodogram\", fontsize=10)\n",
    "                        ax_period.grid(True, alpha=0.3)\n",
    "                        ax_period.legend(fontsize=8)\n",
    "                        \n",
    "                        # Add statistics text with better positioning\n",
    "                        if peak_periods:\n",
    "                            peak_info = '\\n'.join([f'Peak {j+1}: {p:.1f}d (P={pow:.3f})' \n",
    "                                                 for j, (p, pow) in enumerate(zip(peak_periods[:3], peak_powers[:3]))])\n",
    "                            stats_text = f'N={len(t)} points\\nSpan={span:.1f}d\\n{peak_info}'\n",
    "                        else:\n",
    "                            stats_text = f'N={len(t)} points\\nSpan={span:.1f}d\\nNo significant peaks'\n",
    "                        \n",
    "                        # Position the statistics box in the upper left, but lower than reference lines\n",
    "                        ax_period.text(0.02, 0.75, stats_text, \n",
    "                                     transform=ax_period.transAxes, fontsize=7, \n",
    "                                     verticalalignment='top', alpha=0.9,\n",
    "                                     bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"white\", \n",
    "                                             alpha=0.9, edgecolor='gray', linewidth=0.5))\n",
    "                        \n",
    "                        # Print results\n",
    "                        if peak_periods:\n",
    "                            peak_str = ', '.join([f'{p:.2f}d' for p in peak_periods[:3]])\n",
    "                            print(f\"{ds} - {col}: Top periods = {peak_str}\")\n",
    "                        else:\n",
    "                            print(f\"{ds} - {col}: No significant peaks found\")\n",
    "                        \n",
    "                    else:\n",
    "                        ax_period.text(0.5, 0.5, f\"Insufficient time span\\n({span:.1f} days)\", \n",
    "                                     ha='center', va='center', transform=ax_period.transAxes)\n",
    "                else:\n",
    "                    ax_period.text(0.5, 0.5, f\"Insufficient data\\n({len(t)} points)\", \n",
    "                                 ha='center', va='center', transform=ax_period.transAxes)\n",
    "            else:\n",
    "                ax_period.text(0.5, 0.5, \"No data available\", \n",
    "                             ha='center', va='center', transform=ax_period.transAxes)\n",
    "                \n",
    "        except Exception as e:\n",
    "            ax_period.text(0.5, 0.5, f\"Error computing\\nperiodogram:\\n{str(e)[:50]}...\", \n",
    "                         ha='center', va='center', transform=ax_period.transAxes, fontsize=8)\n",
    "            print(f\"Error in {ds} - {col}: {str(e)}\")\n",
    "    \n",
    "    # Set x-labels for bottom row\n",
    "    axes[-1, 0].set_xlabel(\"Time [eMJD]\")\n",
    "    axes[-1, 1].set_xlabel(\"Period [days]\")\n",
    "    \n",
    "    # Add legend to first data plot only\n",
    "    if all_instruments:\n",
    "        handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        axes[0, 0].legend(by_label.values(), by_label.keys(), loc=\"best\", fontsize=8)\n",
    "    \n",
    "    # Set overall title\n",
    "    fig.suptitle(f\"{ds} - Activity Indicators & Lomb-Scargle Periodograms (Inliers Only)\", \n",
    "                 fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = os.path.join(fig_dir, f\"{ds}_activity_LS_periodograms.png\")\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved figure: {fig_path}\")\n",
    "\n",
    "# Apply the function to all datasets\n",
    "print(\"Creating activity plots with periodograms using inliers only...\")\n",
    "for ds, ds_df in df_all.groupby(\"Dataset\"):\n",
    "    plot_activity_with_periodograms(ds, ds_df, fig_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyorbit (Python 3.10.18)",
   "language": "python",
   "name": "pyorbit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
